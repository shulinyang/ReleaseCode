argsï¼š Namespace(datasource='wf_tally', domaintype=3, envdomain=1, gesturelist=[1, 2, 3, 4, 5, 6], gpuloadratio=0.3, gradientreversalrate=0.0, instancelist=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], matlabname=['velocity_bins_freq'], mode='train', nettype='CNN_GRU_wf_tally', numberofpath=5, orientationdomain=3, pathtype='INSTANCE_sobel', patience=10, pcalist=[0, 1, 2], positiondomain=4, receiverlist=[0, 1, 2, 3, 4, 5], serverset='remote', sizeoffeature=64, targettype=1, timelimit=58, traintestratio=0.8, userlist=[1, 2, 3, 4, 5, 6, 7, 8], yaxislength=20)
ed:  [1, 2, 3, 4, 5, 6, 7, 8] pd:  [1, 2, 3, 4, 5] od:  [1, 2, 3, 5, 4]
Loading Data...
domain_type: 3
Loaded Data wf_tally 1 (9600, 58, 6, 20, 3) 4 (9600, 8) 1 (2400, 58, 6, 20, 3)
n_timesteps: 58
Train on 8640 samples, validate on 960 samples
Epoch 1/1000
 - 36s - loss: 1.4961 - acc: 0.3456 - val_loss: 1.2861 - val_acc: 0.4562
Epoch 2/1000
 - 30s - loss: 1.1376 - acc: 0.5250 - val_loss: 0.9516 - val_acc: 0.6354
Epoch 3/1000
 - 30s - loss: 0.8922 - acc: 0.6539 - val_loss: 0.9120 - val_acc: 0.6302
Epoch 4/1000
 - 31s - loss: 0.7139 - acc: 0.7374 - val_loss: 0.8565 - val_acc: 0.6917
Epoch 5/1000
 - 30s - loss: 0.5990 - acc: 0.7826 - val_loss: 0.4715 - val_acc: 0.8333
Epoch 6/1000
 - 30s - loss: 0.4799 - acc: 0.8307 - val_loss: 0.4350 - val_acc: 0.8438
Epoch 7/1000
 - 30s - loss: 0.4088 - acc: 0.8581 - val_loss: 0.4010 - val_acc: 0.8698
Epoch 8/1000
 - 30s - loss: 0.3425 - acc: 0.8800 - val_loss: 0.2962 - val_acc: 0.8938
Epoch 9/1000
 - 30s - loss: 0.2896 - acc: 0.8973 - val_loss: 0.2545 - val_acc: 0.9010
Epoch 10/1000
 - 30s - loss: 0.2484 - acc: 0.9145 - val_loss: 0.2200 - val_acc: 0.9198
Epoch 11/1000
 - 30s - loss: 0.2198 - acc: 0.9244 - val_loss: 0.3575 - val_acc: 0.8896
Epoch 12/1000
 - 30s - loss: 0.1898 - acc: 0.9382 - val_loss: 0.2739 - val_acc: 0.9135
Epoch 13/1000
 - 30s - loss: 0.1595 - acc: 0.9446 - val_loss: 0.1862 - val_acc: 0.9417
Epoch 14/1000
 - 30s - loss: 0.1537 - acc: 0.9486 - val_loss: 0.1931 - val_acc: 0.9396
Epoch 15/1000
 - 31s - loss: 0.1261 - acc: 0.9564 - val_loss: 0.2398 - val_acc: 0.9375
Epoch 16/1000
 - 30s - loss: 0.1194 - acc: 0.9609 - val_loss: 0.1604 - val_acc: 0.9521
Epoch 17/1000
 - 30s - loss: 0.1123 - acc: 0.9626 - val_loss: 0.1496 - val_acc: 0.9573
Epoch 18/1000
 - 30s - loss: 0.0967 - acc: 0.9666 - val_loss: 0.1621 - val_acc: 0.9563
Epoch 19/1000
 - 30s - loss: 0.0842 - acc: 0.9701 - val_loss: 0.1423 - val_acc: 0.9594
Epoch 20/1000
 - 29s - loss: 0.0810 - acc: 0.9735 - val_loss: 0.2090 - val_acc: 0.9417
Epoch 21/1000
 - 29s - loss: 0.0757 - acc: 0.9742 - val_loss: 0.1123 - val_acc: 0.9708
Epoch 22/1000
 - 29s - loss: 0.0663 - acc: 0.9784 - val_loss: 0.1204 - val_acc: 0.9729
Epoch 23/1000
 - 29s - loss: 0.0675 - acc: 0.9777 - val_loss: 0.1301 - val_acc: 0.9594
Epoch 24/1000
 - 29s - loss: 0.0630 - acc: 0.9772 - val_loss: 0.1042 - val_acc: 0.9677
Epoch 25/1000
 - 30s - loss: 0.0558 - acc: 0.9817 - val_loss: 0.1379 - val_acc: 0.9563
Epoch 26/1000
 - 29s - loss: 0.0532 - acc: 0.9834 - val_loss: 0.1644 - val_acc: 0.9583
Epoch 27/1000
 - 29s - loss: 0.0499 - acc: 0.9839 - val_loss: 0.1021 - val_acc: 0.9646
Epoch 28/1000
 - 30s - loss: 0.0424 - acc: 0.9848 - val_loss: 0.1106 - val_acc: 0.9698
Epoch 29/1000
 - 30s - loss: 0.0446 - acc: 0.9839 - val_loss: 0.1315 - val_acc: 0.9615
Epoch 30/1000
 - 31s - loss: 0.0436 - acc: 0.9874 - val_loss: 0.1026 - val_acc: 0.9729
Epoch 31/1000
 - 30s - loss: 0.0450 - acc: 0.9865 - val_loss: 0.0967 - val_acc: 0.9750
Epoch 32/1000
 - 29s - loss: 0.0443 - acc: 0.9858 - val_loss: 0.0892 - val_acc: 0.9760
Epoch 33/1000
 - 29s - loss: 0.0367 - acc: 0.9894 - val_loss: 0.1699 - val_acc: 0.9510
Epoch 34/1000
 - 31s - loss: 0.0374 - acc: 0.9880 - val_loss: 0.0974 - val_acc: 0.9729
Epoch 35/1000
 - 31s - loss: 0.0377 - acc: 0.9870 - val_loss: 0.1089 - val_acc: 0.9750
Epoch 36/1000
 - 30s - loss: 0.0330 - acc: 0.9894 - val_loss: 0.1020 - val_acc: 0.9719
Epoch 37/1000
 - 29s - loss: 0.0297 - acc: 0.9902 - val_loss: 0.1114 - val_acc: 0.9698
Epoch 38/1000
 - 29s - loss: 0.0378 - acc: 0.9874 - val_loss: 0.1115 - val_acc: 0.9719
Epoch 39/1000
 - 29s - loss: 0.0348 - acc: 0.9895 - val_loss: 0.1277 - val_acc: 0.9719
Epoch 40/1000
 - 30s - loss: 0.0294 - acc: 0.9897 - val_loss: 0.1124 - val_acc: 0.9667
Epoch 41/1000
 - 30s - loss: 0.0356 - acc: 0.9896 - val_loss: 0.0973 - val_acc: 0.9750
Epoch 42/1000
 - 31s - loss: 0.0311 - acc: 0.9897 - val_loss: 0.1327 - val_acc: 0.9688
dict_keys(['loss', 'val_loss', 'acc', 'val_acc'])
[[395   1   1   0   1   2]
 [  4 363  12   1   6  14]
 [  3  21 368   3   3   2]
 [ 22   0  95 280   2   1]
 [ 22   7   2   0 355  14]
 [ 10   1   1   0   0 388]]
[[0.9875 0.0025 0.0025 0.     0.0025 0.005 ]
 [0.01   0.9075 0.03   0.0025 0.015  0.035 ]
 [0.0075 0.0525 0.92   0.0075 0.0075 0.005 ]
 [0.055  0.     0.2375 0.7    0.005  0.0025]
 [0.055  0.0175 0.005  0.     0.8875 0.035 ]
 [0.025  0.0025 0.0025 0.     0.     0.97  ]]
metrics: ['loss', 'acc']
Test score: [0.5353174810377095, 0.8954166666666666]
Test loss: 0.5353174810377095
Test accuracy: 0.8954166666666666
Saving model to disk 

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
time_distributed_1 (TimeDist (None, 58, 64)            78400     
_________________________________________________________________
gru_output (GRU)             (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 6)                 774       
=================================================================
Total params: 153,286
Trainable params: 153,286
Non-trainable params: 0
_________________________________________________________________
None
Loading Data...
domain_type: 3
Loaded Data wf_tally 1 (9600, 58, 6, 20, 3) 4 (9600, 8) 1 (2400, 58, 6, 20, 3)
n_timesteps: 58
Train on 8640 samples, validate on 960 samples
Epoch 1/1000
 - 32s - loss: 1.5597 - acc: 0.3170 - val_loss: 1.3171 - val_acc: 0.4385
Epoch 2/1000
 - 29s - loss: 1.1976 - acc: 0.4844 - val_loss: 1.1068 - val_acc: 0.5198
Epoch 3/1000
 - 28s - loss: 1.0380 - acc: 0.5777 - val_loss: 0.8834 - val_acc: 0.6656
Epoch 4/1000
 - 28s - loss: 0.8198 - acc: 0.6821 - val_loss: 0.7189 - val_acc: 0.7521
Epoch 5/1000
 - 29s - loss: 0.6650 - acc: 0.7544 - val_loss: 0.6319 - val_acc: 0.7760
Epoch 6/1000
 - 30s - loss: 0.5521 - acc: 0.7933 - val_loss: 0.5210 - val_acc: 0.8177
Epoch 7/1000
 - 30s - loss: 0.4693 - acc: 0.8284 - val_loss: 0.5442 - val_acc: 0.8229
Epoch 8/1000
 - 30s - loss: 0.3990 - acc: 0.8559 - val_loss: 0.4437 - val_acc: 0.8667
Epoch 9/1000
 - 30s - loss: 0.3343 - acc: 0.8801 - val_loss: 0.3211 - val_acc: 0.9021
Epoch 10/1000
 - 30s - loss: 0.2907 - acc: 0.9002 - val_loss: 0.3651 - val_acc: 0.8812
Epoch 11/1000
 - 28s - loss: 0.2430 - acc: 0.9170 - val_loss: 0.2703 - val_acc: 0.9135
Epoch 12/1000
 - 30s - loss: 0.2108 - acc: 0.9267 - val_loss: 0.2732 - val_acc: 0.9125
Epoch 13/1000
 - 30s - loss: 0.1800 - acc: 0.9367 - val_loss: 0.2853 - val_acc: 0.9073
Epoch 14/1000
 - 29s - loss: 0.1673 - acc: 0.9420 - val_loss: 0.2117 - val_acc: 0.9302
Epoch 15/1000
 - 29s - loss: 0.1420 - acc: 0.9515 - val_loss: 0.2015 - val_acc: 0.9354
Epoch 16/1000
 - 30s - loss: 0.1284 - acc: 0.9556 - val_loss: 0.2067 - val_acc: 0.9333
Epoch 17/1000
 - 29s - loss: 0.1207 - acc: 0.9605 - val_loss: 0.2016 - val_acc: 0.9333
Epoch 18/1000
 - 30s - loss: 0.1040 - acc: 0.9648 - val_loss: 0.1944 - val_acc: 0.9354
Epoch 19/1000
 - 29s - loss: 0.0985 - acc: 0.9657 - val_loss: 0.1559 - val_acc: 0.9552
Epoch 20/1000
 - 29s - loss: 0.0915 - acc: 0.9700 - val_loss: 0.1493 - val_acc: 0.9458
Epoch 21/1000
 - 29s - loss: 0.0804 - acc: 0.9734 - val_loss: 0.1590 - val_acc: 0.9552
Epoch 22/1000
 - 29s - loss: 0.0733 - acc: 0.9752 - val_loss: 0.2396 - val_acc: 0.9417
Epoch 23/1000
 - 30s - loss: 0.0747 - acc: 0.9747 - val_loss: 0.1473 - val_acc: 0.9542
Epoch 24/1000
 - 29s - loss: 0.0652 - acc: 0.9771 - val_loss: 0.2363 - val_acc: 0.9354
Epoch 25/1000
 - 29s - loss: 0.0604 - acc: 0.9811 - val_loss: 0.1558 - val_acc: 0.9552
Epoch 26/1000
 - 28s - loss: 0.0536 - acc: 0.9831 - val_loss: 0.2566 - val_acc: 0.9344
Epoch 27/1000
 - 29s - loss: 0.0587 - acc: 0.9803 - val_loss: 0.1674 - val_acc: 0.9479
Epoch 28/1000
 - 29s - loss: 0.0506 - acc: 0.9832 - val_loss: 0.2561 - val_acc: 0.9292
Epoch 29/1000
 - 29s - loss: 0.0518 - acc: 0.9830 - val_loss: 0.1289 - val_acc: 0.9594
Epoch 30/1000
 - 28s - loss: 0.0460 - acc: 0.9845 - val_loss: 0.1249 - val_acc: 0.9625
Epoch 31/1000
 - 29s - loss: 0.0468 - acc: 0.9840 - val_loss: 0.1063 - val_acc: 0.9708
Epoch 32/1000
 - 28s - loss: 0.0413 - acc: 0.9869 - val_loss: 0.1367 - val_acc: 0.9604
Epoch 33/1000
 - 29s - loss: 0.0402 - acc: 0.9875 - val_loss: 0.0939 - val_acc: 0.9740
Epoch 34/1000
 - 29s - loss: 0.0393 - acc: 0.9860 - val_loss: 0.1782 - val_acc: 0.9573
Epoch 35/1000
 - 29s - loss: 0.0402 - acc: 0.9863 - val_loss: 0.1610 - val_acc: 0.9573
Epoch 36/1000
 - 29s - loss: 0.0415 - acc: 0.9883 - val_loss: 0.1959 - val_acc: 0.9458
Epoch 37/1000
 - 29s - loss: 0.0373 - acc: 0.9873 - val_loss: 0.1056 - val_acc: 0.9708
Epoch 38/1000
 - 28s - loss: 0.0344 - acc: 0.9885 - val_loss: 0.1102 - val_acc: 0.9688
Epoch 39/1000
 - 28s - loss: 0.0357 - acc: 0.9878 - val_loss: 0.0899 - val_acc: 0.9729
Epoch 40/1000
 - 28s - loss: 0.0359 - acc: 0.9870 - val_loss: 0.1302 - val_acc: 0.9625
Epoch 41/1000
 - 28s - loss: 0.0317 - acc: 0.9896 - val_loss: 0.1109 - val_acc: 0.9698
Epoch 42/1000
 - 27s - loss: 0.0339 - acc: 0.9896 - val_loss: 0.1206 - val_acc: 0.9646
Epoch 43/1000
 - 27s - loss: 0.0306 - acc: 0.9905 - val_loss: 0.2603 - val_acc: 0.9417
Epoch 44/1000
 - 27s - loss: 0.0283 - acc: 0.9916 - val_loss: 0.1061 - val_acc: 0.9698
Epoch 45/1000
 - 28s - loss: 0.0236 - acc: 0.9925 - val_loss: 0.1011 - val_acc: 0.9719
Epoch 46/1000
 - 29s - loss: 0.0301 - acc: 0.9914 - val_loss: 0.1297 - val_acc: 0.9698
Epoch 47/1000
 - 30s - loss: 0.0313 - acc: 0.9907 - val_loss: 0.1381 - val_acc: 0.9667
Epoch 48/1000
 - 29s - loss: 0.0253 - acc: 0.9912 - val_loss: 0.0986 - val_acc: 0.9729
Epoch 49/1000
 - 30s - loss: 0.0239 - acc: 0.9924 - val_loss: 0.0923 - val_acc: 0.9792
dict_keys(['loss', 'val_loss', 'acc', 'val_acc'])
[[386  10   1   1   1   1]
 [  2 380   4   1   1  12]
 [  6  41 333  16   2   2]
 [  5   5  60 322   5   3]
 [  9   4   2   1 374  10]
 [  7   9   2   1   1 380]]
[[0.965  0.025  0.0025 0.0025 0.0025 0.0025]
 [0.005  0.95   0.01   0.0025 0.0025 0.03  ]
 [0.015  0.1025 0.8325 0.04   0.005  0.005 ]
 [0.0125 0.0125 0.15   0.805  0.0125 0.0075]
 [0.0225 0.01   0.005  0.0025 0.935  0.025 ]
 [0.0175 0.0225 0.005  0.0025 0.0025 0.95  ]]
metrics: ['loss', 'acc']
Test score: [0.4507748488610438, 0.90625]
Test loss: 0.4507748488610438
Test accuracy: 0.90625
Saving model to disk 

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
time_distributed_2 (TimeDist (None, 58, 64)            78400     
_________________________________________________________________
gru_output (GRU)             (None, 128)               74112     
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 6)                 774       
=================================================================
Total params: 153,286
Trainable params: 153,286
Non-trainable params: 0
_________________________________________________________________
None
Loading Data...
domain_type: 3
Loaded Data wf_tally 1 (9600, 58, 6, 20, 3) 4 (9600, 8) 1 (2400, 58, 6, 20, 3)
n_timesteps: 58
Train on 8640 samples, validate on 960 samples
Epoch 1/1000
 - 29s - loss: 1.4708 - acc: 0.3655 - val_loss: 1.2658 - val_acc: 0.4313
Epoch 2/1000
 - 29s - loss: 1.1737 - acc: 0.5071 - val_loss: 1.0798 - val_acc: 0.5687
Epoch 3/1000
 - 29s - loss: 0.9784 - acc: 0.6014 - val_loss: 0.9395 - val_acc: 0.6406
Epoch 4/1000
 - 27s - loss: 0.7945 - acc: 0.6948 - val_loss: 0.6139 - val_acc: 0.7781
Epoch 5/1000
 - 28s - loss: 0.6470 - acc: 0.7630 - val_loss: 0.5154 - val_acc: 0.8208
Epoch 6/1000
 - 29s - loss: 0.5340 - acc: 0.8063 - val_loss: 0.5151 - val_acc: 0.8177
Epoch 7/1000
 - 29s - loss: 0.4495 - acc: 0.8438 - val_loss: 0.3400 - val_acc: 0.8833
Epoch 8/1000
 - 30s - loss: 0.3658 - acc: 0.8714 - val_loss: 0.2789 - val_acc: 0.9094
Epoch 9/1000
 - 28s - loss: 0.3145 - acc: 0.8920 - val_loss: 0.2956 - val_acc: 0.9031
Epoch 10/1000
 - 30s - loss: 0.2724 - acc: 0.9080 - val_loss: 0.2025 - val_acc: 0.9333
Epoch 11/1000
 - 31s - loss: 0.2318 - acc: 0.9201 - val_loss: 0.1998 - val_acc: 0.9292
Epoch 12/1000
 - 29s - loss: 0.1963 - acc: 0.9321 - val_loss: 0.1413 - val_acc: 0.9594
Epoch 13/1000
 - 30s - loss: 0.1770 - acc: 0.9392 - val_loss: 0.1982 - val_acc: 0.9354
Epoch 14/1000
 - 30s - loss: 0.1572 - acc: 0.9473 - val_loss: 0.1523 - val_acc: 0.9552
Epoch 15/1000
 - 29s - loss: 0.1405 - acc: 0.9515 - val_loss: 0.1724 - val_acc: 0.9510
Epoch 16/1000
 - 28s - loss: 0.1181 - acc: 0.9587 - val_loss: 0.1160 - val_acc: 0.9677
Epoch 17/1000
 - 28s - loss: 0.1095 - acc: 0.9615 - val_loss: 0.1051 - val_acc: 0.9708
Epoch 18/1000
 - 27s - loss: 0.0983 - acc: 0.9672 - val_loss: 0.1549 - val_acc: 0.9510
Epoch 19/1000
 - 28s - loss: 0.1000 - acc: 0.9664 - val_loss: 0.1025 - val_acc: 0.9708
Epoch 20/1000
 - 28s - loss: 0.0812 - acc: 0.9716 - val_loss: 0.1175 - val_acc: 0.9667
Epoch 21/1000
 - 27s - loss: 0.0724 - acc: 0.9733 - val_loss: 0.1086 - val_acc: 0.9688
Epoch 22/1000
 - 28s - loss: 0.0684 - acc: 0.9766 - val_loss: 0.1264 - val_acc: 0.9688
Epoch 23/1000
 - 28s - loss: 0.0657 - acc: 0.9770 - val_loss: 0.0919 - val_acc: 0.9760
Epoch 24/1000
 - 28s - loss: 0.0646 - acc: 0.9789 - val_loss: 0.0883 - val_acc: 0.9750
Epoch 25/1000
 - 27s - loss: 0.0540 - acc: 0.9809 - val_loss: 0.1666 - val_acc: 0.9552
Epoch 26/1000
 - 29s - loss: 0.0570 - acc: 0.9801 - val_loss: 0.1165 - val_acc: 0.9667
Epoch 27/1000
 - 29s - loss: 0.0556 - acc: 0.9822 - val_loss: 0.1401 - val_acc: 0.9625
Epoch 28/1000
 - 29s - loss: 0.0523 - acc: 0.9831 - val_loss: 0.2609 - val_acc: 0.9479
Epoch 29/1000
 - 30s - loss: 0.0458 - acc: 0.9851 - val_loss: 0.1488 - val_acc: 0.9635
Epoch 30/1000
 - 29s - loss: 0.0472 - acc: 0.9841 - val_loss: 0.1576 - val_acc: 0.9625
Epoch 31/1000
 - 30s - loss: 0.0428 - acc: 0.9860 - val_loss: 0.1246 - val_acc: 0.9750
Epoch 32/1000
 - 29s - loss: 0.0345 - acc: 0.9885 - val_loss: 0.1337 - val_acc: 0.9719
Epoch 33/1000
 - 29s - loss: 0.0405 - acc: 0.9865 - val_loss: 0.1556 - val_acc: 0.9646
Epoch 34/1000
 - 28s - loss: 0.0459 - acc: 0.9855 - val_loss: 0.1275 - val_acc: 0.9750
dict_keys(['loss', 'val_loss', 'acc', 'val_acc'])
[[399   1   0   0   0   0]
 [  8 376   2   0   1  13]
 [ 12  42 334   4   5   3]
 [ 28   3 123 236   8   2]
 [ 20   6   2   0 357  15]
 [  7   5   6   1   0 381]]
[[0.9975 0.0025 0.     0.     0.     0.    ]
 [0.02   0.94   0.005  0.     0.0025 0.0325]
 [0.03   0.105  0.835  0.01   0.0125 0.0075]
 [0.07   0.0075 0.3075 0.59   0.02   0.005 ]
 [0.05   0.015  0.005  0.     0.8925 0.0375]
 [0.0175 0.0125 0.015  0.0025 0.     0.9525]]
metrics: ['loss', 'acc']
Test score: [0.6409712653047851, 0.8679166666666667]
Test loss: 0.6409712653047851
Test accuracy: 0.8679166666666667
Saving model to disk 

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
time_distributed_3 (TimeDist (None, 58, 64)            78400     
_________________________________________________________________
gru_output (GRU)             (None, 128)               74112     
_________________________________________________________________
dropout_6 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 6)                 774       
=================================================================
Total params: 153,286
Trainable params: 153,286
Non-trainable params: 0
_________________________________________________________________
None
